This project focuses on facial emotion recognition for elderly individuals, especially those with dementia, where verbal emotional expression is often limited. Instead of using deep learning methods, we adopt a rule-based and geometry-based approach using facial landmarks to provide an interpretable and lightweight solution suitable for small datasets and caregiving scenarios. The system uses MediaPipe FaceMesh to detect facial landmarks from static images and extracts three geometric features: smile ratio, mouth open ratio, and browâ€“eye distance. Based on manually designed and carefully tuned thresholds derived from labeled elderly facial images, emotions are classified into Happy, Surprised, Angry, Neutral, and Pain, with special emphasis on detecting pain-related expressions to assist caregivers in better understanding the emotional states of elderly individuals.
